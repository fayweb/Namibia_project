# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
# ***********************************************************
# Define Column Selection Vectors for Analysis
# ***********************************************************
# ðŸ“Œ Trapping & Field Metadata Variables (rodent_data)
trapping_vars <- c(
"Latitude",
"Longitude",
"Morphology_species",
"Sex",
"Age",
"Weight_g",
"Location_type",
"Date"
)
# ***********************************************************
# 16S Sequencing Variables
# ***********************************************************
# ðŸ§¬ 16S Barcode & Sequencing Metadata
barcode_vars_16s <- c("barcode_16s", "conc_16s__PCR", "Gene")
# ðŸ§ª 16S Taxonomic Assignments
otu_16s_vars <- c(
"tax_id",
"count_16s",
"species",
"genus",
"family",
"order",
"class",
"phylum",
"superkingdom"
)
# ðŸ”¬ Combined 16S Selection Vector
microbiome_16s_vars <- c(barcode_vars_16s, otu_16s_vars)
# ***********************************************************
# 28S Sequencing Variables
# ***********************************************************
# ðŸ§¬ 28S Barcode & Sequencing Metadata
barcode_vars_28s <- c("barcode_28s")
count_vars_28s   <- c("count_28s")
metadata_vars_28s <- c("Date_28s_PCR", "Gene")
# ðŸ§ª 28S Taxonomic Assignments (same structure as 16S)
taxonomy_vars_shared <- c("tax_id", "species", "genus",
"family", "order", "class",
"phylum", "superkingdom")
# ðŸ”¬ Combined 28S Selection Vector
otu_28s_vars <- c(barcode_vars_28s, count_vars_28s,
taxonomy_vars_shared, metadata_vars_28s)
# ***********************************************************
# Part 3: Data Cleaning - Rodent Field Data ----
# ***********************************************************
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
#----------------------------------------------------------*
# 3.1a: Nanodrop DNA Quality Assessment in the Field
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.1a: Archiving early Nanodrop DNA QC (field)...")
#source(file.path(scripts_dir, "preprocessing", "01a_nanodrop_field_qc.R"))
#----------------------------------------------------------*
# 3.3: AMPure Cleanup QC (Marly)
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.3: Processing DNA cleanup QC from AMPure protocol...")
#source(file.path(scripts_dir, "preprocessing", "03_dna_cleaning_qc_marly.R"))
# ***********************************************************
# Part 4: Taxonomic Processing - OTU & Phylogenetic Analysis ----
# ***********************************************************
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Linking barcode names to rodent data frame")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
#----------------------------------------------------------*
# 4.1b: Renamed EMU OTU Tables - Marly vs Melanie
#----------------------------------------------------------*
# ðŸ“„ Documentation:
#   - EMU outputs and filtering description:
#     â–¸ Protocols/Data_processing/EMU_outputs_documentation.md
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1c: Integrate OTU Tables + Taxonomy + Rodent Metadata
#----------------------------------------------------------*
# Purpose:
#   - Clean and pivot Marly's and Melanie's OTU count tables
#   - Join with EMU taxonomy assignments
#   - Integrate with rodent metadata using barcodes
#   - Save fully annotated OTU tables separately for each filtering strategy
#
# ðŸ“„ Script: Scripts/Preprocessing/04a_merge_otu_tables_to_metadata.R
# ðŸ“‚ Outputs:
#   - otu_taxonomy_metadata_marly.csv    (standard filtering)
#   - otu_taxonomy_metadata_melanie.csv (lenient filtering)
message(
"\nðŸ”¹ Step 4.1c: Integrating OTU counts with taxonomy and rodent metadata...")
source(
file.path(scripts_dir, "preprocessing", "04a_merge_otu_tables_to_metadata.R"))
#----------------------------------------------------------*
# 4.1d: Compare EMU Filtering Pipelines
#----------------------------------------------------------*
# This step runs a full RMarkdown comparison between two
# EMU OTU filtering strategies:
#   - Marly's standard filtering
#   - Melanie's lenient filtering
# ðŸ“‚ Outputs:
#   â–¸ HTML report:
# Protocols/Data_processing/04b_compare_filtering_marly_vs_melanie.html
#   â–¸ PDF report:
# Protocols/Data_processing/Comparison_filtering_strategies_Marly_Melanie.pdf
#
# 4.1d: Compare filtering strategies and save report to protocols folder
#message("\nðŸ”¹
#Step 4.1d: Comparing filtering approaches from Marly and Melanie...")
#rmarkdown::render(
# input = file.path(scripts_dir, "preprocessing",
#"04b_compare_filtering_marly_vs_melanie.Rmd"),
#knit_root_dir = project_root,
#  output_file = "04b_compare_filtering_marly_vs_melanie.html",
# output_dir = file.path(project_root, "Protocols", "Data_processing")
#)
#----------------------------------------------------------*
# 4.1e: Select Final Filtering Strategy for Downstream Analysis
#----------------------------------------------------------*
# Based on comparisons in 04b_compare_filtering_marly_vs_melanie.Rmd,
# we selected Marly's standard filtering for all downstream microbiome analyses.
# This script copies the final annotated OTU table and standardizes
# its name for clarity and reproducibility.
# ðŸ“„ Script: Scripts/Preprocessing/04c_select_final_filtering_output.R
# ðŸ“‚ Outputs:
#   - otu_taxonomy_metadata_final.csv
#     (used for diversity, phyloseq, and downstream community analysis)
message("\nðŸ”¹ Step 4.1e: Finalizing selection of
Marly's filtered EMU output...")
source(file.path(scripts_dir, "preprocessing",
"04c_select_final_filtering_output.R"))
#----------------------------------------------------------*
# 4.2: Integrate EMU 28S Output from Emanuel Heitlinger
#----------------------------------------------------------*
# Purpose:
#   - Load 28S EMU output and sample metadata from Emanuel
#   - Filter for rodent samples only
#   - Join with rodent metadata
#   - Annotate and prepare for parasite-focused analysis
#
# ðŸ“„ Script: Scripts/Preprocessing/05a_mouse_parasite_28s_analysis.R
# ðŸ“‚ Outputs:
#   - rodent_data with merged 28S data
#   - Used later for parasite diversity and re-clustering
message("\nðŸ”¹ Step 4.2: Annotating 28S EMU output from Emanuel
and joining to rodent metadata...")
source(file.path(scripts_dir, "preprocessing",
"05a_mouse_parasite_28s_analysis.R"))
# ***********************************************************
# Part 5: Microbiome Community Analysis - 16S & 28S ----
# ***********************************************************
# 5.1: Construct Phyloseq Object (16S) ------------------------
source(file.path(scripts_dir, "Analysis", "0_construct_phyloseq.R"))
# 5.2: Decontamination (Blanks & Controls) -------------------
source(file.path(scripts_dir, "Analysis", "1_decontamination_separates.R"))
# 5.3: Preprocessing / Filtering -----------------------------
source(file.path(scripts_dir, "Analysis", "2_quality_summary_stats.R"))
# 5.4: Alpha Diversity ----------------------------------------
source(file.path(scripts_dir, "Analysis", "3_alpha_diversity.R"))
alpha_df <- estimate_richness(ps, measures = c("Shannon", "Observed", "InvSimpson")) %>%
rownames_to_column("Sample_ID") %>%
left_join(as.data.frame(sample_data(ps)) %>% rownames_to_column("Sample_ID"))
ggplot(alpha_df, aes(x = sample_or_control, y = Shannon, fill = sample_or_control)) +
geom_boxplot(alpha = 0.7) +
geom_jitter(width = 0.2, size = 1.5) +
theme_minimal() +
labs(title = "Shannon Diversity by Sample Type", y = "Shannon Diversity", x = "Sample Type")
message("ðŸŒ± Starting alpha diversity analysis...")
# ------------------------------------------------------------
# Step 1: Load phyloseq object and basic filtering
# ------------------------------------------------------------
ps <- readRDS(file.path(processed_data, "phyloseq_16s_decontaminated.rds"))
ps <- prune_taxa(taxa_sums(ps) > 0, ps)
read_summary <- summary(sample_sums(ps))
message("ðŸ§¬ Read depth range: ", paste0(range(sample_sums(ps)), collapse = " - "))
# ------------------------------------------------------------
# Step 2: Rarefaction Curve (Sample-wise)
# ------------------------------------------------------------
plot_rarefaction_with_filter <- function(physeq_obj, min_sum = 10, rarefy_to = 20000) {
otu_tab <- t(as(otu_table(physeq_obj), "matrix"))
metadata <- data.frame(sample_data(physeq_obj))
# Round to integer counts
otu_tab <- round(otu_tab)
# Replace NAs with 0 and filter
otu_tab[is.na(otu_tab)] <- 0
otu_tab <- otu_tab[rowSums(otu_tab) >= min_sum, ]
metadata <- metadata[rownames(otu_tab), ]
if (nrow(otu_tab) < 2) {
warning("Not enough samples after filtering for rarefaction.")
return(NULL)
}
# Cap rarefaction depth to a safe minimum
rare_depth <- min(min(rowSums(otu_tab)), rarefy_to)
# Assign color
group_colors <- if ("sample_or_control" %in% colnames(metadata)) {
cols <- c("sample" = "black", "control" = "red")
cols[metadata$sample_or_control]
} else {
rainbow(nrow(otu_tab))
}
# Save plot
jpeg(file.path(results_dir, "Figures", "16S_QC", "rarefaction_curve.jpeg"),
width = 8, height = 5, units = "in", res = 300)
vegan::rarecurve(otu_tab, step = 100, label = FALSE,
sample = rare_depth, col = group_colors,
cex = 0.6, main = "Rarefaction Curve by Sample Type")
dev.off()
message("ðŸ“ˆ Rarefaction curve saved successfully.")
}
plot_rarefaction_with_filter(ps)
alpha_df <- estimate_richness(ps, measures = c("Shannon", "Observed", "InvSimpson")) %>%
rownames_to_column("Sample_ID") %>%
left_join(as.data.frame(sample_data(ps)) %>% rownames_to_column("Sample_ID"))
# ***********************************************************
# Title: Namibia Rodent Project - Data Processing & Analysis
# Purpose: This script executes all processing & analysis steps
#          for the rodent microbiome sequencing study.
#
# Authors: Fay Webster, Marly Erazo, Otto Netzel, Lilla Jordan,
#          Emanuel Heitlinger, Conor Noonan, Dong Xia, Melanie Hay
#
# ***********************************************************
# ***********************************************************
# ***********************************************************
# Part 0: 16S Nanopore Preprocessing (External HPC Pipeline)
# ***********************************************************
# Note: The raw 16S Nanopore data were preprocessed outside of R
#       using a shell-based pipeline executed on the MPCDF cluster.
#
# ðŸ§ª Step 0.1: Basecalling & Demultiplexing (Dorado)
# --------------------------------------------------
# Tool: ONT Dorado
# Script: Scripts/Basecalling/dorado_basecall_mpcdf.slurm
#
# Key components:
#   - CUDA module loaded via `module load cuda/11.4`
#   - Basecalling with `--min-qscore 10`
#   - Outputs: BAM files and summary stats
#   - Demultiplexing using `--kit-name EXP-PBC096`
#
# ðŸ“‚ Outputs:
#   - Basecalled reads:         data/raw/ont_fastq/
#   - Summary & BAM:            data/raw/ont_fastq/*.bam, *.txt
# ðŸ§¬ Step 0.2: Quality Filtering & Length Trimming
# --------------------------------------------------
# Filtering performed for full-length 16S reads (1400â€“1800 bp).
# Quality control and stats generated via:
#   - NanoPlot
#   - samtools stats
# Summary metrics (pre- and post-filtering):
#   â–¸ Mean read quality:       Q15.6
#   â–¸ Number of reads:         ~1.57M
#   â–¸ Read length N50:         ~1,393 bp
#   â–¸ Percent reads > Q10:     98.1%
#   â–¸ Percent reads > Q15:     65.1%
#
# ðŸ“Š Quality report:
#   - NanoPlot HTML report (interactive):
#     â–¸ data/raw/16S_sequencing/quality/NanoPlot-report.html
# ðŸ§¬ Step 0.3: Taxonomic Classification (EMU)
# --------------------------------------------------
# Tool: EMU (Exact Mapping of 16S reads)
# Script: Scripts/Basecalling/emu_script.slurm
#
# Key components:
#   - Conda environment activation (`EMU`)
#   - Looping over demultiplexed FASTQ files
#   - Running `emu abundance` with the SILVA database
#
# ðŸ“‚ Outputs:
#   - Taxonomic abundance tables: data/processed/ont_emu_abundance/
#   - One `.tsv` file per sample with tax_id counts and relative abundances
# ðŸ“„ Documentation:
#   - Full pipeline details, filtering criteria, and HPC command logs:
#     â–¸ Protocols/Data_processing/README_16s_data_preprocessing.pdf
# ðŸ§¾ Step 0.4: Sample Tracking Metadata (PCR + Pooling)
# --------------------------------------------------
# The following files document the 16S plate setup, robot buffer input,
# and pooling decisions used to prepare samples for sequencing.
# These are **not used in the downstream R analysis**, but archived
# for provenance and reproducibility.
# ðŸ“„ Documents:
#   - 16S PCR plate metadata:
#   data/raw/16S_sequencing/16s_PCR/20231123_PCR_final.xlsx
#   - Opentrons robot buffer input:
#         data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Buffer
#CSV_19-03-2024_namibia_plate16s.csv
#   - Opentrons robot sample input:
#         data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample
#CSV_19-03-2024_namibia_plate16s.csv
#   - Sample pooling design:
#                data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/
#Sample_pooling_CSV_03-04-2024.csv
# ***********************************************************
# Part 1: Set Standard Settings & Load Libraries ----
# ***********************************************************
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl, qgraph, vegan, ggvenn,
decontam, microbiome, microViz, microbiomeAnalysis, ggraph, ggtext,
ComplexHeatmap, corncob)
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl, qgraph, vegan, ggvenn,
decontam, microbiome, microViz, microbiomeAnalysis, ggraph, ggtext, corncob)
# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
# ðŸ“Œ Trapping & Field Metadata Variables (rodent_data)
trapping_vars <- c(
"Latitude",
"Longitude",
"Morphology_species",
"Sex",
"Age",
"Weight_g",
"Location_type",
"Date"
)
# ðŸ§¬ 16S Barcode & Sequencing Metadata
barcode_vars_16s <- c("barcode_16s", "conc_16s__PCR", "Gene")
# ðŸ§ª 16S Taxonomic Assignments
otu_16s_vars <- c(
"tax_id",
"count_16s",
"species",
"genus",
"family",
"order",
"class",
"phylum",
"superkingdom"
)
# ðŸ”¬ Combined 16S Selection Vector
microbiome_16s_vars <- c(barcode_vars_16s, otu_16s_vars)
# ðŸ§¬ 28S Barcode & Sequencing Metadata
barcode_vars_28s <- c("barcode_28s")
count_vars_28s   <- c("count_28s")
metadata_vars_28s <- c("Date_28s_PCR", "Gene")
# ðŸ§ª 28S Taxonomic Assignments (same structure as 16S)
taxonomy_vars_shared <- c("tax_id", "species", "genus",
"family", "order", "class",
"phylum", "superkingdom")
# ðŸ”¬ Combined 28S Selection Vector
otu_28s_vars <- c(barcode_vars_28s, count_vars_28s,
taxonomy_vars_shared, metadata_vars_28s)
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
# ***********************************************************
# Part 4: Taxonomic Processing - OTU & Phylogenetic Analysis ----
# ***********************************************************
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Linking barcode names to rodent data frame")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
# Purpose:
#   - Clean and pivot Marly's and Melanie's OTU count tables
#   - Join with EMU taxonomy assignments
#   - Integrate with rodent metadata using barcodes
#   - Save fully annotated OTU tables separately for each filtering strategy
#
# ðŸ“„ Script: Scripts/Preprocessing/04a_merge_otu_tables_to_metadata.R
# ðŸ“‚ Outputs:
#   - otu_taxonomy_metadata_marly.csv    (standard filtering)
#   - otu_taxonomy_metadata_melanie.csv (lenient filtering)
message(
"\nðŸ”¹ Step 4.1c: Integrating OTU counts with taxonomy and rodent metadata...")
source(
file.path(scripts_dir, "preprocessing", "04a_merge_otu_tables_to_metadata.R"))
# 4.1e: Select Final Filtering Strategy for Downstream Analysis
#----------------------------------------------------------*
# Based on comparisons in 04b_compare_filtering_marly_vs_melanie.Rmd,
# we selected Marly's standard filtering for all downstream microbiome analyses.
# This script copies the final annotated OTU table and standardizes
# its name for clarity and reproducibility.
# ðŸ“„ Script: Scripts/Preprocessing/04c_select_final_filtering_output.R
# ðŸ“‚ Outputs:
#   - otu_taxonomy_metadata_final.csv
#     (used for diversity, phyloseq, and downstream community analysis)
message("\nðŸ”¹ Step 4.1e: Finalizing selection of
Marly's filtered EMU output...")
source(file.path(scripts_dir, "preprocessing",
"04c_select_final_filtering_output.R"))
# Purpose:
#   - Load 28S EMU output and sample metadata from Emanuel
#   - Filter for rodent samples only
#   - Join with rodent metadata
#   - Annotate and prepare for parasite-focused analysis
#
# ðŸ“„ Script: Scripts/Preprocessing/05a_mouse_parasite_28s_analysis.R
# ðŸ“‚ Outputs:
#   - rodent_data with merged 28S data
#   - Used later for parasite diversity and re-clustering
message("\nðŸ”¹ Step 4.2: Annotating 28S EMU output from Emanuel
and joining to rodent metadata...")
source(file.path(scripts_dir, "preprocessing",
"05a_mouse_parasite_28s_analysis.R"))
# 5.1: Construct Phyloseq Object (16S) ------------------------
source(file.path(scripts_dir, "Analysis", "0_construct_phyloseq.R"))
# 5.2: Decontamination (Blanks & Controls) -------------------
source(file.path(scripts_dir, "Analysis", "1_decontamination_separates.R"))
# 5.3: Preprocessing / Filtering -----------------------------
source(file.path(scripts_dir, "Analysis", "2_quality_summary_stats.R"))
# 5.4: Alpha Diversity ----------------------------------------
source(file.path(scripts_dir, "Analysis", "3_alpha_diversity.R"))
message("ðŸ§­ Starting beta diversity ordination...")
# Load object
ps <- readRDS(file.path(processed_data, "phyloseq_16s_decontaminated.rds"))
# Transform to relative abundance
ps_rel <- transform_sample_counts(ps, function(x) x / sum(x))
# Compute Bray-Curtis distance
bray_dist <- phyloseq::distance(ps_rel, method = "bray")
# NMDS ordination
nmds_ord <- ordinate(ps_rel, method = "NMDS", distance = bray_dist)
# Plot NMDS
p_nmds <- plot_ordination(ps_rel, nmds_ord, color = "sample_or_control") +
geom_point(size = 3, alpha = 0.8) +
theme_minimal(base_size = 14) +
labs(title = "NMDS Ordination by Sample Type", color = "Sample Type")
# Save
ggsave(file.path(results_dir, "Figures", "16S_Beta", "nmds_sample_type.jpeg"),
plot = p_nmds, width = 6, height = 4, dpi = 300)
message("âœ… NMDS ordination saved.")
rm(ps, ps_rel, bray_dist, nmds_ord, p_nmds)
message("ðŸ”¬ Starting CLR-transformed PCA for genus-level taxa...")
# Load object
ps <- readRDS(file.path(processed_data, "phyloseq_16s_decontaminated.rds"))
# Aggregate to genus level
ps_genus <- tax_glom(ps, taxrank = "genus")
# CLR transformation
ps_clr <- microbiome::transform(ps_genus, "clr")
# Ordinate with PCA
pca_ord <- ordinate(ps_clr, method = "PCA")
# Plot PCA
p_pca <- plot_ordination(ps_clr, pca_ord, color = "sample_or_control") +
geom_point(size = 3, alpha = 0.8) +
theme_minimal(base_size = 14) +
labs(title = "PCA (CLR-transformed Genus)", color = "Sample Type")
message("âœ… PCA ordination saved.")
# Save
ggsave(file.path(results_dir, "Figures", "16S_Beta", "pca_clr_taxa.jpeg"),
plot = p_pca, width = 6, height = 4, dpi = 300)
# Plot PCA
p_pca <- plot_ordination(ps_clr, pca_ord, color = "sample_or_control") +
geom_point(size = 3, alpha = 0.8) +
theme_minimal(base_size = 14) +
labs(title = "PCA (CLR-transformed Genus)", color = "Sample Type")
# Load object
ps <- readRDS(file.path(processed_data, "phyloseq_16s_decontaminated.rds"))
# Aggregate to genus level
ps_genus <- tax_glom(ps, taxrank = "genus")
# CLR transform using microbiome package (returns a phyloseq object)
ps_clr <- microbiome::transform(ps_genus, "clr")
# Ordinate with PCA
pca_ord <- ordinate(ps_clr, method = "RDA")  # use RDA, not PCA, for CLR-transformed data
# Plot
p_pca <- plot_ordination(ps_clr, pca_ord, color = "sample_or_control") +
geom_point(size = 3, alpha = 0.8) +
theme_minimal(base_size = 14) +
labs(title = "PCA (CLR-transformed Genus)", color = "Sample Type")
# Save
ggsave(file.path(results_dir, "Figures", "16S_Beta", "pca_clr_taxa.jpeg"),
plot = p_pca, width = 6, height = 4, dpi = 300)
