#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.3: Processing DNA cleanup QC from AMPure protocol...")
source(file.path(scripts_dir, "preprocessing", "03_dna_cleaning_qc_marly.R"))
raw <- read_excel("data/raw/20241125_marly_extra_DNA_cleaning_roedeanst_DNA.xlsx",
sheet = "Plate_set-up DNA Plate16s r",
skip = 1)  # Skip the description row
# Rename the useful columns based on the real headers
colnames(raw)[c(1, 2, 3, 10, 11, 17, 18, 19, 20, 21, 22, 23)] <- c(
"Sample_ID", "Well", "Qubit_ng_ul_pre", "Nanodrop_ng_ul_pre", "A260_pre",
"Qubit_ng_ul_post", "Nanodrop_ng_ul_post", "Nanodrop_unit_post",
"A260_post", "A280_post", "Ratio_260_280_post", "Ratio_260_230_post"
)
df_cleaning <- raw %>%
select(
Sample_ID            = Collection...1,
Well                 = well...2,
Qubit_ng_ul_pre      = Qubit (ng/Âµl) DNA conc. original sample,
df_cleaning <- raw %>%
select(
Sample_ID            = Collection...1,
Well                 = well...2,
Qubit_ng_ul_pre      = Qubit (ng/Âµl) DNA conc. original sample,
raw <- read_excel("data/raw/20241125_marly_extra_DNA_cleaning_roedeanst_DNA.xlsx",
sheet = "Plate_set-up DNA Plate16s r",
skip = 1)  # Skip the description row
# Rename the useful columns based on the real headers
colnames(raw)[c(1, 2, 3, 10, 11, 17, 18, 19, 20, 21, 22, 23)] <- c(
"Sample_ID", "Well", "Qubit_ng_ul_pre", "Nanodrop_ng_ul_pre", "A260_pre",
"Qubit_ng_ul_post", "Nanodrop_ng_ul_post", "Nanodrop_unit_post",
"A260_post", "A280_post", "Ratio_260_280_post", "Ratio_260_230_post"
)
df_cleaning <- raw %>%
select(
Sample_ID            = Collection...1,
Well                 = well...2,
Qubit_ng_ul_pre      = Qubit (ng/Âµl) DNA conc. original sample,
df_cleaning <- df_cleaning %>%
mutate(across(where(is.character) & !c(Sample_ID, Well), as.numeric)) %>%  # catch stray character columns
mutate(across(c(Qubit_ng_ul_pre), as.numeric))  #_
df_cleaning <- raw %>%
select(
Sample_ID            = Collection...1,
Well                 = well...2,
Qubit_ng_ul_pre      = Qubit (ng/Âµl) DNA conc. original sample,
df_cleaning <- raw %>%
select(
Sample_ID            = `Collection...1`,
Well                 = `well...2`,
Qubit_ng_ul_pre      = `Qubit (ng/Âµl) DNA conc. original sample`,
Nanodrop_ng_ul_pre   = `Nanodrop original sample`,
Qubit_ng_ul_post     = `Qubit (ng/Âµl) after cleaning with the AMPure beas (15ul of sample and 15 ul of beads, elution in 30ul DNAse free water)`,
Nanodrop_ng_ul_post  = `Nanodrop after cleaning with the AMPure beas (15ul of sample and 15 ul of beads, elution in 30ul DNAse free water)`,
A260_post            = `A260...22`,
A280_post            = `A280...23`,
Ratio_260_280_post   = `260/280...24`,
Ratio_260_230_post   = `260/230...25`
)
glimpse(raw)
raw <- read_excel("data/raw/20241125_marly_extra_DNA_cleaning_roedeanst_DNA.xlsx",
sheet = "Plate_set-up DNA Plate16s r",
skip = 1)  # Skip the description row
# Rename the useful columns based on the real headers
colnames(raw)[c(1, 2, 3, 10, 11, 17, 18, 19, 20, 21, 22, 23)] <- c(
"Sample_ID", "Well", "Qubit_ng_ul_pre", "Nanodrop_ng_ul_pre", "A260_pre",
"Qubit_ng_ul_post", "Nanodrop_ng_ul_post", "Nanodrop_unit_post",
"A260_post", "A280_post", "Ratio_260_280_post", "Ratio_260_230_post"
)
glimpse(raw)
raw <- read_excel("data/raw/20241125_marly_extra_DNA_cleaning_roedeanst_DNA.xlsx",
sheet = "Plate_set-up DNA Plate16s r",
skip = 1)  # Skip the description row
# Rename the useful columns based on the real headers
colnames(raw)[c(1, 2, 3, 10, 11, 17, 18, 19, 20, 21, 22, 23)] <- c(
"Sample_ID", "Well", "Qubit_ng_ul_pre", "Nanodrop_ng_ul_pre", "A260_pre",
"Qubit_ng_ul_post", "Nanodrop_ng_ul_post", "Nanodrop_unit_post",
"A260_post", "A280_post", "Ratio_260_280_post", "Ratio_260_230_post"
)
df_cleaning <- raw %>%
select(
Sample_ID            = `Collection...1`,
Well                 = `well...2`,
Qubit_ng_ul_pre      = `Qubit (ng/Âµl) DNA conc. original sample`,
Nanodrop_ng_ul_pre   = `Nanodrop original sample`,
Qubit_ng_ul_post     = `Qubit (ng/Âµl) after cleaning with the AMPure beas (15ul of sample and 15 ul of beads, elution in 30ul DNAse free water)`,
Nanodrop_ng_ul_post  = `Nanodrop after cleaning with the AMPure beas (15ul of sample and 15 ul of beads, elution in 30ul DNAse free water)`,
A260_post            = `A260...22`,
A280_post            = `A280...23`,
Ratio_260_280_post   = `260/280...24`,
Ratio_260_230_post   = `260/230...25`
)
df_cleaning <- raw %>%
transmute(
Sample_ID           = Sample_ID,
Well                = Well,
Qubit_ng_ul_pre     = as.numeric(Qubit_ng_ul_pre),
Nanodrop_ng_ul_pre  = Nanodrop_ng_ul_pre,
A260_pre            = A260_pre,
Qubit_ng_ul_post    = Nanodrop_unit_post,
Nanodrop_ng_ul_post = A260_post,
A260_post           = as.numeric(A260_post),
A280_post           = as.numeric(Ratio_260_280_post),
Ratio_260_280_post  = `260/280...24`,
Ratio_260_230_post  = `260/230...25`
)
write_csv(df_cleaning, "data/processed/dna_cleanup_marly_2023.csv")
message("âœ… Cleaned DNA cleanup log saved.")
# Plot Qubit pre vs post
p1 <- ggplot(df_cleaning, aes(x = Qubit_ng_ul_pre, y = Qubit_ng_ul_post)) +
geom_point() +
labs(title = "Qubit: Before vs After Cleanup", x = "Before (ng/Âµl)", y = "After (ng/Âµl)") +
theme_minimal()
ggsave("results/figures/dna_cleaning/qubit_pre_vs_post.png", p1, width = 7, height = 6)
p1
# Plot 260/280 vs 260/230
p2 <- ggplot(df_cleaning, aes(x = Ratio_260_280_post, y = Ratio_260_230_post)) +
geom_point() +
labs(title = "Post-Cleanup DNA Purity Ratios", x = "260/280", y = "260/230") +
theme_minimal()
p2
ggsave("results/figures/dna_cleaning/post_cleanup_ratios.png", p2, width = 7, height = 6)
message("âœ… DNA cleanup QC plots saved.")
View(p1)
# ***********************************************************
# Title: Namibia Rodent Project - Data Processing & Analysis
# Purpose: This script executes all processing & analysis steps
#          for the rodent microbiome sequencing study.
#
# Authors: Fay Webster, Marly Erazo, Otto Netzel, Lilla Jordan,
#          Emanuel Heitlinger, Conor Noonan, Dong Xia, Melanie Hay
#
# ***********************************************************
# ***********************************************************
# ***********************************************************
# Part 0: 16S Nanopore Preprocessing (External HPC Pipeline)
# ***********************************************************
# Note: The raw 16S Nanopore data were preprocessed outside of R
#       using a shell-based pipeline executed on the MPCDF cluster.
#
# ðŸ§ª Step 0.1: Basecalling & Demultiplexing (Dorado)
# --------------------------------------------------
# Tool: ONT Dorado
# Script: Scripts/Basecalling/dorado_basecall_mpcdf.slurm
#
# Key components:
#   - CUDA module loaded via `module load cuda/11.4`
#   - Basecalling with `--min-qscore 10`
#   - Outputs: BAM files and summary stats
#   - Demultiplexing using `--kit-name EXP-PBC096`
#
# ðŸ“‚ Outputs:
#   - Basecalled reads:         data/raw/ont_fastq/
#   - Summary & BAM:            data/raw/ont_fastq/*.bam, *.txt
# ðŸ§¬ Step 0.2: Quality Filtering & Length Trimming
# --------------------------------------------------
# Filtering performed for full-length 16S reads (1400â€“1800 bp).
# Quality control and stats generated via:
#   - NanoPlot
#   - samtools stats
# Summary metrics (pre- and post-filtering):
#   â–¸ Mean read quality:       Q15.6
#   â–¸ Number of reads:         ~1.57M
#   â–¸ Read length N50:         ~1,393 bp
#   â–¸ Percent reads > Q10:     98.1%
#   â–¸ Percent reads > Q15:     65.1%
#
# ðŸ“Š Quality report:
#   - NanoPlot HTML report (interactive):
#     â–¸ data/raw/16S_sequencing/quality/NanoPlot-report.html
# ðŸ§¬ Step 0.3: Taxonomic Classification (EMU)
# --------------------------------------------------
# Tool: EMU (Exact Mapping of 16S reads)
# Script: Scripts/Basecalling/emu_script.slurm
#
# Key components:
#   - Conda environment activation (`EMU`)
#   - Looping over demultiplexed FASTQ files
#   - Running `emu abundance` with the SILVA database
#
# ðŸ“‚ Outputs:
#   - Taxonomic abundance tables: data/processed/ont_emu_abundance/
#   - One `.tsv` file per sample with tax_id counts and relative abundances
# ðŸ“„ Documentation:
#   - Full pipeline details, filtering criteria, and HPC command logs:
#     â–¸ Protocols/Data_processing/README_16s_data_preprocessing.pdf
# ðŸ§¾ Step 0.4: Sample Tracking Metadata (PCR + Pooling)
# --------------------------------------------------
# The following files document the 16S plate setup, robot buffer input,
# and pooling decisions used to prepare samples for sequencing.
# These are **not used in the downstream R analysis**, but archived
# for provenance and reproducibility.
# ðŸ“„ Documents:
#   - 16S PCR plate metadata:            data/raw/16S_sequencing/16s_PCR/20231123_PCR_final.xlsx
#   - Opentrons robot buffer input:      data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Buffer CSV_19-03-2024_namibia_plate16s.csv
#   - Opentrons robot sample input:      data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample CSV_19-03-2024_namibia_plate16s.csv
#   - Sample pooling design:             data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample_pooling_CSV_03-04-2024.csv
# ***********************************************************
# Part 1: Set Standard Settings & Load Libraries ----
# ***********************************************************
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl
)
# ***********************************************************
# Part 2: Define Project File Paths ----
# ***********************************************************
# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
# ***********************************************************
# Part 3: Data Cleaning - Rodent Field Data ----
# ***********************************************************
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
#----------------------------------------------------------*
# 3.1a: Nanodrop DNA Quality Assessment in the Field
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.1a: Archiving early Nanodrop DNA QC (field)...")
#source(file.path(scripts_dir, "preprocessing", "01a_nanodrop_field_qc.R"))
#----------------------------------------------------------*
# 3.3: AMPure Cleanup QC (Marly)
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.3: Processing DNA cleanup QC from AMPure protocol...")
source(file.path(scripts_dir, "preprocessing", "03_dna_cleaning_qc_marly.R"))
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Renaming EMU OTU table columns using sample metadata...")
# Define paths
otu_path <- file.path("data", "processed", "ont_emu_abundance", "emu-combined-abundance-tax_id-counts.tsv")
ref_path <- file.path("data", "raw", "16S_sequencing", "reference_files", "barcode_sample_reference.csv")
output_path <- file.path("data", "processed", "phyloseq_elements", "otu_table.tsv")
# Read files
otu_table <- read_tsv(otu_path)
ref <- read_csv(ref_path)
# Read files
otu_table <- read_tsv(otu_path)
# Define paths
otu_path <- file.path("data", "processed", "ont_emu_abundance", "emu-combined-abundance-tax_id-counts.tsv")
ref_path <- file.path("data", "raw", "16S_sequencing", "reference_files", "barcode_sample_reference.csv")
output_path <- file.path("data", "processed", "phyloseq_elements", "otu_table.tsv")
# Define paths
otu_path <- file.path("data", "processed", "ont_emu_abundance", "emu-combined-abundance-tax_id-counts.tsv")
otu_path
ref_path <- file.path("data", "raw", "16S_sequencing", "reference_files", "barcode_sample_reference.csv")
View(df_cleaning)
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl
)
# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
View(rodent_data)
glimpse(rodent_data)
# ***********************************************************
# Title: Link Barcode IDs to Rodent Metadata
# Purpose: Merge barcode-to-sample reference with cleaned field metadata
# ***********************************************************
# Load barcode-sample reference file
barcode_ref <- read_csv("data/processed/16S_sequencing/barcode_sample_metadata.csv")
# ***********************************************************
# Title: Link Barcode IDs to Rodent Metadata
# Purpose: Merge barcode-to-sample reference with cleaned field metadata
# ***********************************************************
# Load barcode-sample reference file
barcode_ref <- read_csv("data/processed/16S_sequencing/barcode_sample_metadata.csv")
# ***********************************************************
# Title: Link Barcode IDs to Rodent Metadata
# Purpose: Merge barcode-to-sample reference with cleaned field metadata
# ***********************************************************
# Load barcode-sample reference file
barcode_ref <- read_csv("data/processed/16S_sequencing/barcode_sample_metadata.csv")
# ***********************************************************
# Title: Link Barcode IDs to Rodent Metadata
# Purpose: Merge barcode-to-sample reference with cleaned field metadata
# ***********************************************************
# Load barcode-sample reference file
barcode_ref <- read_csv("data/raw/16S_sequencing/reference_files/barcode_sample_metadata.csv")
# ***********************************************************
# Title: Link Barcode IDs to Rodent Metadata
# Purpose: Merge barcode-to-sample reference with cleaned field metadata
# ***********************************************************
# Load barcode-sample reference file
barcode_ref <- read_csv("data/raw/16S_sequencing/reference_files/barcode_sample_reference.csv")
View(barcode_ref)
glimpse(rodent_data)
glimpse(barcode_ref)
View(barcode_ref)
# ***********************************************************
# Title: Link Barcode IDs to Rodent Metadata
# Purpose: Merge barcode-to-sample reference with cleaned field metadata
# ***********************************************************
# Load barcode-sample reference file
barcode_ref <- read_csv("data/raw/16S_sequencing/reference_files/barcode_sample_reference.csv")
View(barcode_ref)
barcode_ref$barcode
?str_remove
barcode_ref$barcode <- str_remove(
string = barcode_ref$barcode,
pattern = "e17a8f2887894f8d7becdbeaafbc97db14bc8e66_EXP-PBC096_")
View(barcode_ref)
glimpse(barcode_ref)
# remove repate sample name column
barcode_ref <- barcode_ref %>%
dplyr::select(-Sample_ID...6)
View(barcode_ref)
?rename
View(rodent_data)
# rename now barcode_ref column sample id
barcode_ref <- barcode_ref %>%
dplyr::rename(Sample_ID = Sample_ID...5)
View(barcode_ref)
# rename now barcode_ref column sample id
barcode_ref <- barcode_ref %>%
dplyr::rename(Sample_ID = Sample_ID...5) %>%
dplyr::select(Sample_ID, conc_16s__PCR, barcode)
# ***********************************************************
# Title: Link Barcode IDs to Rodent Metadata
# Purpose: Merge barcode-to-sample reference with cleaned field metadata
# ***********************************************************
# Load barcode-sample reference file
barcode_ref <- read_csv("data/raw/16S_sequencing/reference_files/barcode_sample_reference.csv")
# remove the unecessary string in front of the barcode names
barcode_ref$barcode <- str_remove(
string = barcode_ref$barcode,
pattern = "e17a8f2887894f8d7becdbeaafbc97db14bc8e66_EXP-PBC096_")
# remove repate sample name column
barcode_ref <- barcode_ref %>%
dplyr::select(-Sample_ID...6)
# rename now barcode_ref column sample id
barcode_ref <- barcode_ref %>%
dplyr::rename(Sample_ID = Sample_ID...5) %>%
dplyr::select(Sample_ID, conc_16s__PCR, barcode)
# Merge by Sample_ID
rodent_data <- left_join(rodent_data, barcode_ref, by = "Sample_ID")
View(rodent_data)
# ***********************************************************
# Title: Namibia Rodent Project - Data Processing & Analysis
# Purpose: This script executes all processing & analysis steps
#          for the rodent microbiome sequencing study.
#
# Authors: Fay Webster, Marly Erazo, Otto Netzel, Lilla Jordan,
#          Emanuel Heitlinger, Conor Noonan, Dong Xia, Melanie Hay
#
# ***********************************************************
# ***********************************************************
# ***********************************************************
# Part 0: 16S Nanopore Preprocessing (External HPC Pipeline)
# ***********************************************************
# Note: The raw 16S Nanopore data were preprocessed outside of R
#       using a shell-based pipeline executed on the MPCDF cluster.
#
# ðŸ§ª Step 0.1: Basecalling & Demultiplexing (Dorado)
# --------------------------------------------------
# Tool: ONT Dorado
# Script: Scripts/Basecalling/dorado_basecall_mpcdf.slurm
#
# Key components:
#   - CUDA module loaded via `module load cuda/11.4`
#   - Basecalling with `--min-qscore 10`
#   - Outputs: BAM files and summary stats
#   - Demultiplexing using `--kit-name EXP-PBC096`
#
# ðŸ“‚ Outputs:
#   - Basecalled reads:         data/raw/ont_fastq/
#   - Summary & BAM:            data/raw/ont_fastq/*.bam, *.txt
# ðŸ§¬ Step 0.2: Quality Filtering & Length Trimming
# --------------------------------------------------
# Filtering performed for full-length 16S reads (1400â€“1800 bp).
# Quality control and stats generated via:
#   - NanoPlot
#   - samtools stats
# Summary metrics (pre- and post-filtering):
#   â–¸ Mean read quality:       Q15.6
#   â–¸ Number of reads:         ~1.57M
#   â–¸ Read length N50:         ~1,393 bp
#   â–¸ Percent reads > Q10:     98.1%
#   â–¸ Percent reads > Q15:     65.1%
#
# ðŸ“Š Quality report:
#   - NanoPlot HTML report (interactive):
#     â–¸ data/raw/16S_sequencing/quality/NanoPlot-report.html
# ðŸ§¬ Step 0.3: Taxonomic Classification (EMU)
# --------------------------------------------------
# Tool: EMU (Exact Mapping of 16S reads)
# Script: Scripts/Basecalling/emu_script.slurm
#
# Key components:
#   - Conda environment activation (`EMU`)
#   - Looping over demultiplexed FASTQ files
#   - Running `emu abundance` with the SILVA database
#
# ðŸ“‚ Outputs:
#   - Taxonomic abundance tables: data/processed/ont_emu_abundance/
#   - One `.tsv` file per sample with tax_id counts and relative abundances
# ðŸ“„ Documentation:
#   - Full pipeline details, filtering criteria, and HPC command logs:
#     â–¸ Protocols/Data_processing/README_16s_data_preprocessing.pdf
# ðŸ§¾ Step 0.4: Sample Tracking Metadata (PCR + Pooling)
# --------------------------------------------------
# The following files document the 16S plate setup, robot buffer input,
# and pooling decisions used to prepare samples for sequencing.
# These are **not used in the downstream R analysis**, but archived
# for provenance and reproducibility.
# ðŸ“„ Documents:
#   - 16S PCR plate metadata:            data/raw/16S_sequencing/16s_PCR/20231123_PCR_final.xlsx
#   - Opentrons robot buffer input:      data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Buffer CSV_19-03-2024_namibia_plate16s.csv
#   - Opentrons robot sample input:      data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample CSV_19-03-2024_namibia_plate16s.csv
#   - Sample pooling design:             data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample_pooling_CSV_03-04-2024.csv
# ***********************************************************
# Part 1: Set Standard Settings & Load Libraries ----
# ***********************************************************
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl
)
# ***********************************************************
# Part 2: Define Project File Paths ----
# ***********************************************************
# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
# ***********************************************************
# Part 3: Data Cleaning - Rodent Field Data ----
# ***********************************************************
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
#----------------------------------------------------------*
# 3.1a: Nanodrop DNA Quality Assessment in the Field
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.1a: Archiving early Nanodrop DNA QC (field)...")
#source(file.path(scripts_dir, "preprocessing", "01a_nanodrop_field_qc.R"))
#----------------------------------------------------------*
# 3.3: AMPure Cleanup QC (Marly)
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.3: Processing DNA cleanup QC from AMPure protocol...")
#source(file.path(scripts_dir, "preprocessing", "03_dna_cleaning_qc_marly.R"))
# ***********************************************************
# Part 4: Taxonomic Processing - OTU & Phylogenetic Analysis ----
# ***********************************************************
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Renaming EMU OTU table columns using sample metadata...")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
