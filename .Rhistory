#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.1a: Archiving early Nanodrop DNA QC (field)...")
#source(file.path(scripts_dir, "preprocessing", "01a_nanodrop_field_qc.R"))
#----------------------------------------------------------*
# 3.3: AMPure Cleanup QC (Marly)
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.3: Processing DNA cleanup QC from AMPure protocol...")
#source(file.path(scripts_dir, "preprocessing", "03_dna_cleaning_qc_marly.R"))
# ***********************************************************
# Part 4: Taxonomic Processing - OTU & Phylogenetic Analysis ----
# ***********************************************************
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Linking barcode names to rodent data frame")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
#----------------------------------------------------------*
# 4.1b: Renamed EMU OTU Tables - Marly vs Melanie
#----------------------------------------------------------*
# ðŸ“„ Documentation:
#   - EMU outputs and filtering description:
#     â–¸ Protocols/Data_processing/EMU_outputs_documentation.md
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1c: Integrate OTU Tables + Taxonomy + Rodent Metadata
#----------------------------------------------------------*
# Purpose:
#   - Clean and pivot Marly's and Melanie's OTU count tables
#   - Join with EMU taxonomy assignments
#   - Integrate with rodent metadata using barcodes
#   - Save fully annotated OTU tables separately for each filtering strategy
#
# ðŸ“„ Script: Scripts/Preprocessing/04a_merge_otu_tables_to_metadata.R
# ðŸ“‚ Outputs:
#   - otu_taxonomy_metadata_marly.csv    (standard filtering)
#   - otu_taxonomy_metadata_melanie.csv (lenient filtering)
message(
"\nðŸ”¹ Step 4.1c: Integrating OTU counts with taxonomy and rodent metadata...")
source(
file.path(scripts_dir, "preprocessing", "04a_merge_otu_tables_to_metadata.R"))
# Quick check of structure
glimpse(otu_marly)
glimpse(otu_melanie)
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv("Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
otu_melanie <- read.csv("Data/processed/EMU_output/melanie_lenient_filtering/otu_taxonomy_metadata_melanie.csv")
# Quick check of structure
glimpse(otu_marly)
glimpse(otu_melanie)
# Add a filtering label to each dataset
otu_marly$filtering <- "Marly_standard"
otu_melanie$filtering <- "Melanie_lenient"
View(otu_melanie)
# Bind both datasets
otu_combined <- dplyr::bind_rows(otu_marly, otu_melanie)
# Summarize total reads per sample
read_depth <- otu_combined %>%
dplyr::group_by(barcode, filtering) %>%
dplyr::summarise(total_reads = sum(count), .groups = "drop")
# Summarize total reads per sample
read_depth <- otu_combined %>%
group_by(barcode, filtering) %>%
summarise(total_reads = sum(count, na.rm = TRUE), .groups = "drop")
rlang::last_trace()
# Summarize total reads per sample
read_depth <- otu_combined %>%
group_by(barcode, filtering) %>%
summarise(total_reads = sum(count, na.rm = TRUE), .groups = "drop")
str(otu_combined$count)
View(otu_combined)
# Summarize reads per barcode separately
reads_marly <- otu_marly %>%
group_by(barcode) %>%
summarise(total_reads_marly = sum(count_marly, na.rm = TRUE))
reads
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv("Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
otu_melanie <- read.csv("Data/processed/EMU_output/melanie_lenient_filtering/otu_taxonomy_metadata_melanie.csv")
# Quick check of structure
glimpse(otu_marly)
glimpse(otu_melanie)
# Add a filtering label to each dataset
otu_marly$filtering <- "Marly_standard"
otu_melanie$filtering <- "Melanie_lenient"
# Summarize reads per barcode separately
reads_marly <- otu_marly %>%
group_by(barcode) %>%
summarise(total_reads_marly = sum(count_marly, na.rm = TRUE))
reads_melanie <- otu_melanie %>%
group_by(barcode) %>%
summarise(total_reads_melanie = sum(count_melanie, na.rm = TRUE))
# Merge summaries to compare
read_depth_comparison <- full_join(reads_marly, reads_melanie, by = "barcode") %>%
pivot_longer(cols = starts_with("total_reads"), names_to = "filtering", values_to = "total_reads") %>%
mutate(filtering = recode(filtering,
"total_reads_marly" = "Marly (standard)",
"total_reads_melanie" = "Melanie (lenient)"))
# Plot comparison
ggplot(read_depth_comparison, aes(x = reorder(barcode, -total_reads), y = total_reads, fill = filtering)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Read Depth per Sample by Filtering Strategy",
x = "Sample Barcode", y = "Total Reads") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Plot comparison
ggplot(read_depth_comparison, aes(x = reorder(barcode, -total_reads), y = total_reads, fill = filtering)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Read Depth per Sample by Filtering Strategy",
x = "Sample Barcode", y = "Total Reads") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Total read counts across all samples
sum_marly <- sum(otu_marly$count_marly, na.rm = TRUE)
sum_melanie <- sum(otu_melanie$count_melanie, na.rm = TRUE)
# Display
tibble(
Filtering = c("Marly (standard)", "Melanie (lenient)"),
Total_Reads = c(sum_marly, sum_melanie)
)
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv("Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
otu_melanie <- read.csv("Data/processed/EMU_output/melanie_lenient_filtering/otu_taxonomy_metadata_melanie.csv")
# Quick check of structure
glimpse(otu_marly)
glimpse(otu_melanie)
View(otu_marly)
View(otu_marly_full)
gc()
# ***********************************************************
# Title: Namibia Rodent Project - Data Processing & Analysis
# Purpose: This script executes all processing & analysis steps
#          for the rodent microbiome sequencing study.
#
# Authors: Fay Webster, Marly Erazo, Otto Netzel, Lilla Jordan,
#          Emanuel Heitlinger, Conor Noonan, Dong Xia, Melanie Hay
#
# ***********************************************************
# ***********************************************************
# ***********************************************************
# Part 0: 16S Nanopore Preprocessing (External HPC Pipeline)
# ***********************************************************
# Note: The raw 16S Nanopore data were preprocessed outside of R
#       using a shell-based pipeline executed on the MPCDF cluster.
#
# ðŸ§ª Step 0.1: Basecalling & Demultiplexing (Dorado)
# --------------------------------------------------
# Tool: ONT Dorado
# Script: Scripts/Basecalling/dorado_basecall_mpcdf.slurm
#
# Key components:
#   - CUDA module loaded via `module load cuda/11.4`
#   - Basecalling with `--min-qscore 10`
#   - Outputs: BAM files and summary stats
#   - Demultiplexing using `--kit-name EXP-PBC096`
#
# ðŸ“‚ Outputs:
#   - Basecalled reads:         data/raw/ont_fastq/
#   - Summary & BAM:            data/raw/ont_fastq/*.bam, *.txt
# ðŸ§¬ Step 0.2: Quality Filtering & Length Trimming
# --------------------------------------------------
# Filtering performed for full-length 16S reads (1400â€“1800 bp).
# Quality control and stats generated via:
#   - NanoPlot
#   - samtools stats
# Summary metrics (pre- and post-filtering):
#   â–¸ Mean read quality:       Q15.6
#   â–¸ Number of reads:         ~1.57M
#   â–¸ Read length N50:         ~1,393 bp
#   â–¸ Percent reads > Q10:     98.1%
#   â–¸ Percent reads > Q15:     65.1%
#
# ðŸ“Š Quality report:
#   - NanoPlot HTML report (interactive):
#     â–¸ data/raw/16S_sequencing/quality/NanoPlot-report.html
# ðŸ§¬ Step 0.3: Taxonomic Classification (EMU)
# --------------------------------------------------
# Tool: EMU (Exact Mapping of 16S reads)
# Script: Scripts/Basecalling/emu_script.slurm
#
# Key components:
#   - Conda environment activation (`EMU`)
#   - Looping over demultiplexed FASTQ files
#   - Running `emu abundance` with the SILVA database
#
# ðŸ“‚ Outputs:
#   - Taxonomic abundance tables: data/processed/ont_emu_abundance/
#   - One `.tsv` file per sample with tax_id counts and relative abundances
# ðŸ“„ Documentation:
#   - Full pipeline details, filtering criteria, and HPC command logs:
#     â–¸ Protocols/Data_processing/README_16s_data_preprocessing.pdf
# ðŸ§¾ Step 0.4: Sample Tracking Metadata (PCR + Pooling)
# --------------------------------------------------
# The following files document the 16S plate setup, robot buffer input,
# and pooling decisions used to prepare samples for sequencing.
# These are **not used in the downstream R analysis**, but archived
# for provenance and reproducibility.
# ðŸ“„ Documents:
#   - 16S PCR plate metadata:
#   data/raw/16S_sequencing/16s_PCR/20231123_PCR_final.xlsx
#   - Opentrons robot buffer input:
#         data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Buffer CSV_19-03-2024_namibia_plate16s.csv
#   - Opentrons robot sample input:
#         data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample CSV_19-03-2024_namibia_plate16s.csv
#   - Sample pooling design:
#                data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample_pooling_CSV_03-04-2024.csv
# ***********************************************************
# Part 1: Set Standard Settings & Load Libraries ----
# ***********************************************************
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl, qgraph
)
# ***********************************************************
# Part 2: Define Project File Paths ----
# ***********************************************************
# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
# create vectors for selecting relevant columns in the downstream analysis
# Define vector of trapping-relevant columns from rodent_data
trapping_vars <- c(
"Latitude",
"Longitude",
"Morphology_species",
"Sex",
"Age",
"Weight_g",
"Location_type",
"Date"
)
# Define vector of barcode/sequencing-relevant columns
barcode_vars <- c(
"conc_16s__PCR",
"barcode"
)
# ***********************************************************
# Part 3: Data Cleaning - Rodent Field Data ----
# ***********************************************************
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
#----------------------------------------------------------*
# 3.1a: Nanodrop DNA Quality Assessment in the Field
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.1a: Archiving early Nanodrop DNA QC (field)...")
#source(file.path(scripts_dir, "preprocessing", "01a_nanodrop_field_qc.R"))
#----------------------------------------------------------*
# 3.3: AMPure Cleanup QC (Marly)
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.3: Processing DNA cleanup QC from AMPure protocol...")
#source(file.path(scripts_dir, "preprocessing", "03_dna_cleaning_qc_marly.R"))
# ***********************************************************
# Part 4: Taxonomic Processing - OTU & Phylogenetic Analysis ----
# ***********************************************************
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Linking barcode names to rodent data frame")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
#----------------------------------------------------------*
# 4.1b: Renamed EMU OTU Tables - Marly vs Melanie
#----------------------------------------------------------*
# ðŸ“„ Documentation:
#   - EMU outputs and filtering description:
#     â–¸ Protocols/Data_processing/EMU_outputs_documentation.md
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1c: Integrate OTU Tables + Taxonomy + Rodent Metadata
#----------------------------------------------------------*
# Purpose:
#   - Clean and pivot Marly's and Melanie's OTU count tables
#   - Join with EMU taxonomy assignments
#   - Integrate with rodent metadata using barcodes
#   - Save fully annotated OTU tables separately for each filtering strategy
#
# ðŸ“„ Script: Scripts/Preprocessing/04a_merge_otu_tables_to_metadata.R
# ðŸ“‚ Outputs:
#   - otu_taxonomy_metadata_marly.csv    (standard filtering)
#   - otu_taxonomy_metadata_melanie.csv (lenient filtering)
# Paths to files
otu_marly_path <- "data/processed/EMU_output/marly_standard_filtering/otu_counts_marly_standard.tsv"
otu_melanie_path <- "data/processed/EMU_output/melanie_lenient_filtering/otu_counts_melanie_lenient.tsv"
# Load
otu_marly <- read_tsv(otu_marly_path)
otu_melanie <- read_tsv(otu_melanie_path)
View(otu_melanie)
View(otu_melanie)
View(otu_melanie)
View(otu_marly)
# Load barcode metadata (already cleaned and integrated into rodent_data)
barcode_vector <- unique(rodent_data$barcode)
# Clean and pivot Marly's OTU table
otu_marly_long <- otu_marly %>%
rename_with(~ str_remove(.x, "e17a8f2887894f8d7becdbeaafbc97db14bc8e66_EXP-PBC096_")) %>%
pivot_longer(-tax_id, names_to = "barcode", values_to = "count_marly") %>%
filter(barcode %in% barcode_vector)
# Clean and pivot Melanie's OTU table
otu_melanie_long <- otu_melanie %>%
rename_with(~ str_remove(.x, "e17a8f2887894f8d7becdbeaafbc97db14bc8e66_EXP-PBC096_")) %>%
pivot_longer(-tax_id, names_to = "barcode", values_to = "count_melanie") %>%
filter(barcode %in% barcode_vector)
message("âœ… Merged long-format OTU counts from Marly & Melanie saved to: data/processed/EMU_output/otu_counts_long_combined.csv")
#----------------------------------------------------------*
# Step 4.1c: Load EMU Taxonomy Tables (Marly vs Melanie)
#----------------------------------------------------------*
message("ðŸ”¹ Loading taxonomy tables for Marly and Melanie...")
tax_marly_path   <- file.path(processed_data, "EMU_output", "marly_standard_filtering", "taxonomy_marly_standard.tsv")
tax_melanie_path <- file.path(processed_data, "EMU_output", "melanie_lenient_filtering", "taxonomy_melanie_lenient.tsv")
tax_marly   <- read_tsv(tax_marly_path, show_col_types = FALSE)
tax_melanie <- read_tsv(tax_melanie_path, show_col_types = FALSE)
#----------------------------------------------------------*
# Step 4.1d: Merge OTU counts with taxonomy
#----------------------------------------------------------*
message("ðŸ”¹ Merging OTU counts with taxonomy tables...")
otu_marly_annotated <- otu_marly_long %>%
left_join(tax_marly, by = "tax_id")
otu_melanie_annotated <- otu_melanie_long %>%
left_join(tax_melanie, by = "tax_id")
#----------------------------------------------------------*
# Step 4.1e: Merge annotated OTU + taxonomy with rodent metadata
#----------------------------------------------------------*
message("ðŸ”¹ Merging annotated OTU counts with rodent metadata...")
otu_marly_full <- otu_marly_annotated %>%
left_join(rodent_data, by = "barcode")
otu_melanie_full <- otu_melanie_annotated %>%
left_join(rodent_data, by = "barcode")
#----------------------------------------------------------*
# Step 4.1f: Save integrated datasets
#----------------------------------------------------------*
message("ðŸ’¾ Saving merged OTU + taxonomy + metadata tables...")
write_csv(otu_marly_full,
file.path(processed_data, "EMU_output", "marly_standard_filtering",
"otu_taxonomy_metadata_marly.csv"))
write_csv(otu_melanie_full,
file.path(processed_data, "EMU_output", "melanie_lenient_filtering",
"otu_taxonomy_metadata_melanie.csv"))
# remove unecessary files
rm(otu_marly, otu_marly_annotated, otu_marly_long, otu_marly_path,
otu_melanie, otu_melanie_annotated, otu_melanie_long, otu_melanie_path,
otu_merged, tax_marly, tax_melanie)
View(otu_marly_full)
View(otu_melanie_full)
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv("Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
otu_melanie <- read.csv("Data/processed/EMU_output/melanie_lenient_filtering/otu_taxonomy_metadata_melanie.csv")
# Quick check of structure
glimpse(otu_marly)
glimpse(otu_melanie)
# Add a filtering label to each dataset
otu_marly$filtering <- "Marly_standard"
otu_melanie$filtering <- "Melanie_lenient"
# Summarize reads per barcode separately
reads_marly <- otu_marly %>%
group_by(barcode) %>%
summarise(total_reads_marly = sum(count_marly, na.rm = TRUE))
reads_melanie <- otu_melanie %>%
group_by(barcode) %>%
summarise(total_reads_melanie = sum(count_melanie, na.rm = TRUE))
View(reads_marly)
View(reads_melanie)
# Merge summaries to compare
read_depth_comparison <- full_join(reads_marly, reads_melanie, by = "barcode") %>%
pivot_longer(cols = starts_with("total_reads"), names_to = "filtering", values_to = "total_reads") %>%
mutate(filtering = recode(filtering,
"total_reads_marly" = "Marly (standard)",
"total_reads_melanie" = "Melanie (lenient)"))
# Plot comparison
ggplot(read_depth_comparison, aes(x = reorder(barcode, -total_reads), y = total_reads, fill = filtering)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Read Depth per Sample by Filtering Strategy",
x = "Sample Barcode", y = "Total Reads") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
summary(otu_marly$count_marly)
summary(otu_melanie$count_melanie)
# Display
tibble(
Filtering = c("Marly (standard)", "Melanie (lenient)"),
Total_Reads = c(sum_marly, sum_melanie)
)
# Total read counts across all samples
sum_marly <- sum(otu_marly$count_marly, na.rm = TRUE)
sum_melanie <- sum(otu_melanie$count_melanie, na.rm = TRUE)
# Display
tibble(
Filtering = c("Marly (standard)", "Melanie (lenient)"),
Total_Reads = c(sum_marly, sum_melanie)
)
# Join on tax_id + barcode to directly compare
otu_compare <- full_join(
otu_marly %>% select(tax_id, barcode, count_marly),
otu_melanie %>% select(tax_id, barcode, count_melanie),
by = c("tax_id", "barcode")
)
# Calculate difference
otu_compare <- otu_compare %>%
mutate(diff = count_melanie - count_marly)
# How many entries are different?
otu_compare %>% filter(!is.na(diff) & diff != 0) %>% nrow()
# Plot comparison
ggplot(read_depth_comparison, aes(x = reorder(barcode, -total_reads), y = total_reads, fill = filtering)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Read Depth per Sample by Filtering Strategy",
x = "Sample Barcode", y = "Total Reads") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Summarise total reads per sample for each filtering strategy
reads_marly <- otu_marly %>%
group_by(barcode) %>%
summarise(reads_marly = sum(count_marly, na.rm = TRUE))
reads_melanie <- otu_melanie %>%
group_by(barcode) %>%
summarise(reads_melanie = sum(count_melanie, na.rm = TRUE))
# Join and calculate differences
reads_compare <- left_join(reads_marly, reads_melanie, by = "barcode") %>%
mutate(diff = reads_melanie - reads_marly)
# Plot read depth difference per sample
ggplot(reads_compare, aes(x = reorder(barcode, -diff), y = diff)) +
geom_col(fill = "steelblue") +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(title = "Difference in Read Depth per Sample (Melanie - Marly)",
x = "Sample Barcode", y = "Read Count Difference") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(reads_compare, aes(x = reorder(barcode, -diff), y = diff)) +
geom_col(fill = "steelblue") +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(title = "Difference in Read Depth per Sample (Melanie - Marly)",
x = "Sample Barcode", y = "Read Count Difference") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Plot read depth difference per sample
ggplot(reads_compare, aes(x = reorder(barcode, -diff), y = diff)) +
geom_col(fill = "steelblue") +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(title = "Difference in Read Depth per Sample (Melanie - Marly)",
x = "Sample Barcode", y = "Read Count Difference") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(reads_compare, aes(x = reorder(barcode, -diff), y = diff)) +
geom_col(fill = "steelblue") +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(title = "Difference in Read Depth per Sample (Melanie - Marly)",
x = "Sample Barcode", y = "Read Count Difference") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Load required libraries
library(tidyverse)
library(ggplot2)
library(janitor)
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv("Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv("Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv("/Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
otu_melanie <- read.csv("/Data/processed/EMU_output/melanie_lenient_filtering/otu_taxonomy_metadata_melanie.csv")
otu_melanie <- read.csv("/Data/processed/EMU_output/melanie_lenient_filtering/otu_taxonomy_metadata_melanie.csv/")
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv("/Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv/")
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv(file = "Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv(file = "Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
# Load required libraries
library(tidyverse)
library(ggplot2)
library(janitor)
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv(file = "Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
getwd("")
setwd("Data/processed/EMU_output/")
setwd("~/GitHub/Namibia_project")
# Load required libraries
library(tidyverse)
library(ggplot2)
library(janitor)
setwd("Data/processed/EMU_output/")
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv(file = "Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
otu_melanie <- read.csv("/Data/processed/EMU_output/melanie_lenient_filtering/otu_taxonomy_metadata_melanie.csv/")
otu_melanie <- read.csv("Data/processed/EMU_output/melanie_lenient_filtering/otu_taxonomy_metadata_melanie.csv")
# Load required libraries
library(tidyverse)
library(ggplot2)
library(janitor)
# Read merged OTU + taxonomy + metadata files
otu_marly <- read.csv(file = "Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
# Read merged OTU + taxonomy + metadata files
otu_marly <- read_csv(file = "Data/processed/EMU_output/marly_standard_filtering/otu_taxonomy_metadata_marly.csv")
