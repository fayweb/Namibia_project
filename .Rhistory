# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
#----------------------------------------------------------*
# 3.1a: Nanodrop DNA Quality Assessment in the Field
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.1a: Archiving early Nanodrop DNA QC (field)...")
#source(file.path(scripts_dir, "preprocessing", "01a_nanodrop_field_qc.R"))
#----------------------------------------------------------*
# 3.3: AMPure Cleanup QC (Marly)
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.3: Processing DNA cleanup QC from AMPure protocol...")
#source(file.path(scripts_dir, "preprocessing", "03_dna_cleaning_qc_marly.R"))
# ***********************************************************
# Part 4: Taxonomic Processing - OTU & Phylogenetic Analysis ----
# ***********************************************************
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Linking barcode names to rodent data frame")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
#----------------------------------------------------------*
# 4.1b: Renamed EMU OTU Tables - Marly vs Melanie
#----------------------------------------------------------*
# ðŸ“„ Documentation:
#   - EMU outputs and filtering description:
#     â–¸ Protocols/Data_processing/EMU_outputs_documentation.md
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1c: Integrate OTU Tables + Taxonomy + Rodent Metadata
#----------------------------------------------------------*
# Purpose:
#   - Clean and pivot Marly's and Melanie's OTU count tables
#   - Join with EMU taxonomy assignments
#   - Integrate with rodent metadata using barcodes
#   - Save fully annotated OTU tables separately for each filtering strategy
#
# ðŸ“„ Script: Scripts/Preprocessing/04a_merge_otu_tables_to_metadata.R
# ðŸ“‚ Outputs:
#   - otu_taxonomy_metadata_marly.csv    (standard filtering)
#   - otu_taxonomy_metadata_melanie.csv (lenient filtering)
message(
"\nðŸ”¹ Step 4.1c: Integrating OTU counts with taxonomy and rodent metadata...")
source(
file.path(scripts_dir, "preprocessing", "04a_merge_otu_tables_to_metadata.R"))
#   â–¸ Rarefaction curve visualisation
#   â–¸ NMDS ordination (Bray-Curtis beta diversity)
#
# ðŸ“‚ Outputs:
#   â–¸ HTML report:
# Protocols/Data_processing/04b_compare_filtering_marly_vs_melanie.html
#   â–¸ PDF report:
# Protocols/Data_processing/Comparison_filtering_strategies_Marly_Melanie.pdf
#
# 4.1d: Compare filtering strategies and save report to protocols folder
message("\nðŸ”¹ Step 4.1d: Comparing filtering approaches from Marly and Melanie...")
rmarkdown::render(
input = file.path(scripts_dir, "preprocessing", "04b_compare_filtering_marly_vs_melanie.Rmd"),
knit_root_dir = project_root,
output_file = "04b_compare_filtering_marly_vs_melanie.html",
output_dir = file.path(project_root, "Protocols", "Data_processing")
)
# ***********************************************************
# Title: Namibia Rodent Project - Data Processing & Analysis
# Purpose: This script executes all processing & analysis steps
#          for the rodent microbiome sequencing study.
#
# Authors: Fay Webster, Marly Erazo, Otto Netzel, Lilla Jordan,
#          Emanuel Heitlinger, Conor Noonan, Dong Xia, Melanie Hay
#
# ***********************************************************
# ***********************************************************
# ***********************************************************
# Part 0: 16S Nanopore Preprocessing (External HPC Pipeline)
# ***********************************************************
# Note: The raw 16S Nanopore data were preprocessed outside of R
#       using a shell-based pipeline executed on the MPCDF cluster.
#
# ðŸ§ª Step 0.1: Basecalling & Demultiplexing (Dorado)
# --------------------------------------------------
# Tool: ONT Dorado
# Script: Scripts/Basecalling/dorado_basecall_mpcdf.slurm
#
# Key components:
#   - CUDA module loaded via `module load cuda/11.4`
#   - Basecalling with `--min-qscore 10`
#   - Outputs: BAM files and summary stats
#   - Demultiplexing using `--kit-name EXP-PBC096`
#
# ðŸ“‚ Outputs:
#   - Basecalled reads:         data/raw/ont_fastq/
#   - Summary & BAM:            data/raw/ont_fastq/*.bam, *.txt
# ðŸ§¬ Step 0.2: Quality Filtering & Length Trimming
# --------------------------------------------------
# Filtering performed for full-length 16S reads (1400â€“1800 bp).
# Quality control and stats generated via:
#   - NanoPlot
#   - samtools stats
# Summary metrics (pre- and post-filtering):
#   â–¸ Mean read quality:       Q15.6
#   â–¸ Number of reads:         ~1.57M
#   â–¸ Read length N50:         ~1,393 bp
#   â–¸ Percent reads > Q10:     98.1%
#   â–¸ Percent reads > Q15:     65.1%
#
# ðŸ“Š Quality report:
#   - NanoPlot HTML report (interactive):
#     â–¸ data/raw/16S_sequencing/quality/NanoPlot-report.html
# ðŸ§¬ Step 0.3: Taxonomic Classification (EMU)
# --------------------------------------------------
# Tool: EMU (Exact Mapping of 16S reads)
# Script: Scripts/Basecalling/emu_script.slurm
#
# Key components:
#   - Conda environment activation (`EMU`)
#   - Looping over demultiplexed FASTQ files
#   - Running `emu abundance` with the SILVA database
#
# ðŸ“‚ Outputs:
#   - Taxonomic abundance tables: data/processed/ont_emu_abundance/
#   - One `.tsv` file per sample with tax_id counts and relative abundances
# ðŸ“„ Documentation:
#   - Full pipeline details, filtering criteria, and HPC command logs:
#     â–¸ Protocols/Data_processing/README_16s_data_preprocessing.pdf
# ðŸ§¾ Step 0.4: Sample Tracking Metadata (PCR + Pooling)
# --------------------------------------------------
# The following files document the 16S plate setup, robot buffer input,
# and pooling decisions used to prepare samples for sequencing.
# These are **not used in the downstream R analysis**, but archived
# for provenance and reproducibility.
# ðŸ“„ Documents:
#   - 16S PCR plate metadata:
#   data/raw/16S_sequencing/16s_PCR/20231123_PCR_final.xlsx
#   - Opentrons robot buffer input:
#         data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Buffer CSV_19-03-2024_namibia_plate16s.csv
#   - Opentrons robot sample input:
#         data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample CSV_19-03-2024_namibia_plate16s.csv
#   - Sample pooling design:
#                data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample_pooling_CSV_03-04-2024.csv
# ***********************************************************
# Part 1: Set Standard Settings & Load Libraries ----
# ***********************************************************
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl, qgraph, vegan
)
# ***********************************************************
# Part 2: Define Project File Paths ----
# ***********************************************************
# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
# create vectors for selecting relevant columns in the downstream analysis
# Define vector of trapping-relevant columns from rodent_data
trapping_vars <- c(
"Latitude",
"Longitude",
"Morphology_species",
"Sex",
"Age",
"Weight_g",
"Location_type",
"Date"
)
# Define vector of barcode/sequencing-relevant columns
barcode_vars <- c(
"conc_16s__PCR",
"barcode"
)
# ***********************************************************
# Part 3: Data Cleaning - Rodent Field Data ----
# ***********************************************************
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
#----------------------------------------------------------*
# 3.1a: Nanodrop DNA Quality Assessment in the Field
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.1a: Archiving early Nanodrop DNA QC (field)...")
#source(file.path(scripts_dir, "preprocessing", "01a_nanodrop_field_qc.R"))
#----------------------------------------------------------*
# 3.3: AMPure Cleanup QC (Marly)
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.3: Processing DNA cleanup QC from AMPure protocol...")
#source(file.path(scripts_dir, "preprocessing", "03_dna_cleaning_qc_marly.R"))
# ***********************************************************
# Part 4: Taxonomic Processing - OTU & Phylogenetic Analysis ----
# ***********************************************************
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Linking barcode names to rodent data frame")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
#----------------------------------------------------------*
# 4.1b: Renamed EMU OTU Tables - Marly vs Melanie
#----------------------------------------------------------*
# ðŸ“„ Documentation:
#   - EMU outputs and filtering description:
#     â–¸ Protocols/Data_processing/EMU_outputs_documentation.md
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1c: Integrate OTU Tables + Taxonomy + Rodent Metadata
#----------------------------------------------------------*
# Purpose:
#   - Clean and pivot Marly's and Melanie's OTU count tables
#   - Join with EMU taxonomy assignments
#   - Integrate with rodent metadata using barcodes
#   - Save fully annotated OTU tables separately for each filtering strategy
#
# ðŸ“„ Script: Scripts/Preprocessing/04a_merge_otu_tables_to_metadata.R
# ðŸ“‚ Outputs:
#   - otu_taxonomy_metadata_marly.csv    (standard filtering)
#   - otu_taxonomy_metadata_melanie.csv (lenient filtering)
message(
"\nðŸ”¹ Step 4.1c: Integrating OTU counts with taxonomy and rodent metadata...")
source(
file.path(scripts_dir, "preprocessing", "04a_merge_otu_tables_to_metadata.R"))
#----------------------------------------------------------*
# 4.1d: Compare EMU Filtering Pipelines
#----------------------------------------------------------*
# This step runs a full RMarkdown comparison between two
# EMU OTU filtering strategies:
#   - Marly's standard filtering
#   - Melanie's lenient filtering
#
# The script performs:
#   â–¸ Read depth summaries
#   â–¸ Alpha diversity comparison (richness, Shannon)
#   â–¸ Rare taxa quantification
#   â–¸ Phylum-level taxonomic composition
#   â–¸ Rarefaction curve visualisation
#   â–¸ NMDS ordination (Bray-Curtis beta diversity)
#
# ðŸ“‚ Outputs:
#   â–¸ HTML report:
# Protocols/Data_processing/04b_compare_filtering_marly_vs_melanie.html
#   â–¸ PDF report:
# Protocols/Data_processing/Comparison_filtering_strategies_Marly_Melanie.pdf
#
# ***********************************************************
# Title: Namibia Rodent Project - Data Processing & Analysis
# Purpose: This script executes all processing & analysis steps
#          for the rodent microbiome sequencing study.
#
# Authors: Fay Webster, Marly Erazo, Otto Netzel, Lilla Jordan,
#          Emanuel Heitlinger, Conor Noonan, Dong Xia, Melanie Hay
#
# ***********************************************************
# ***********************************************************
# ***********************************************************
# Part 0: 16S Nanopore Preprocessing (External HPC Pipeline)
# ***********************************************************
# Note: The raw 16S Nanopore data were preprocessed outside of R
#       using a shell-based pipeline executed on the MPCDF cluster.
#
# ðŸ§ª Step 0.1: Basecalling & Demultiplexing (Dorado)
# --------------------------------------------------
# Tool: ONT Dorado
# Script: Scripts/Basecalling/dorado_basecall_mpcdf.slurm
#
# Key components:
#   - CUDA module loaded via `module load cuda/11.4`
#   - Basecalling with `--min-qscore 10`
#   - Outputs: BAM files and summary stats
#   - Demultiplexing using `--kit-name EXP-PBC096`
#
# ðŸ“‚ Outputs:
#   - Basecalled reads:         data/raw/ont_fastq/
#   - Summary & BAM:            data/raw/ont_fastq/*.bam, *.txt
# ðŸ§¬ Step 0.2: Quality Filtering & Length Trimming
# --------------------------------------------------
# Filtering performed for full-length 16S reads (1400â€“1800 bp).
# Quality control and stats generated via:
#   - NanoPlot
#   - samtools stats
# Summary metrics (pre- and post-filtering):
#   â–¸ Mean read quality:       Q15.6
#   â–¸ Number of reads:         ~1.57M
#   â–¸ Read length N50:         ~1,393 bp
#   â–¸ Percent reads > Q10:     98.1%
#   â–¸ Percent reads > Q15:     65.1%
#
# ðŸ“Š Quality report:
#   - NanoPlot HTML report (interactive):
#     â–¸ data/raw/16S_sequencing/quality/NanoPlot-report.html
# ðŸ§¬ Step 0.3: Taxonomic Classification (EMU)
# --------------------------------------------------
# Tool: EMU (Exact Mapping of 16S reads)
# Script: Scripts/Basecalling/emu_script.slurm
#
# Key components:
#   - Conda environment activation (`EMU`)
#   - Looping over demultiplexed FASTQ files
#   - Running `emu abundance` with the SILVA database
#
# ðŸ“‚ Outputs:
#   - Taxonomic abundance tables: data/processed/ont_emu_abundance/
#   - One `.tsv` file per sample with tax_id counts and relative abundances
# ðŸ“„ Documentation:
#   - Full pipeline details, filtering criteria, and HPC command logs:
#     â–¸ Protocols/Data_processing/README_16s_data_preprocessing.pdf
# ðŸ§¾ Step 0.4: Sample Tracking Metadata (PCR + Pooling)
# --------------------------------------------------
# The following files document the 16S plate setup, robot buffer input,
# and pooling decisions used to prepare samples for sequencing.
# These are **not used in the downstream R analysis**, but archived
# for provenance and reproducibility.
# ðŸ“„ Documents:
#   - 16S PCR plate metadata:
#   data/raw/16S_sequencing/16s_PCR/20231123_PCR_final.xlsx
#   - Opentrons robot buffer input:
#         data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Buffer CSV_19-03-2024_namibia_plate16s.csv
#   - Opentrons robot sample input:
#         data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample CSV_19-03-2024_namibia_plate16s.csv
#   - Sample pooling design:
#                data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample_pooling_CSV_03-04-2024.csv
# ***********************************************************
# Part 1: Set Standard Settings & Load Libraries ----
# ***********************************************************
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl, qgraph, vegan
)
# ***********************************************************
# Part 2: Define Project File Paths ----
# ***********************************************************
# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
# create vectors for selecting relevant columns in the downstream analysis
# Define vector of trapping-relevant columns from rodent_data
trapping_vars <- c(
"Latitude",
"Longitude",
"Morphology_species",
"Sex",
"Age",
"Weight_g",
"Location_type",
"Date"
)
# Define vector of barcode/sequencing-relevant columns
barcode_vars <- c(
"conc_16s__PCR",
"barcode"
)
# ***********************************************************
# Part 3: Data Cleaning - Rodent Field Data ----
# ***********************************************************
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
#----------------------------------------------------------*
# 3.1a: Nanodrop DNA Quality Assessment in the Field
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.1a: Archiving early Nanodrop DNA QC (field)...")
#source(file.path(scripts_dir, "preprocessing", "01a_nanodrop_field_qc.R"))
#----------------------------------------------------------*
# 3.3: AMPure Cleanup QC (Marly)
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.3: Processing DNA cleanup QC from AMPure protocol...")
#source(file.path(scripts_dir, "preprocessing", "03_dna_cleaning_qc_marly.R"))
# ***********************************************************
# Part 4: Taxonomic Processing - OTU & Phylogenetic Analysis ----
# ***********************************************************
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Linking barcode names to rodent data frame")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
#----------------------------------------------------------*
# 4.1b: Renamed EMU OTU Tables - Marly vs Melanie
#----------------------------------------------------------*
# ðŸ“„ Documentation:
#   - EMU outputs and filtering description:
#     â–¸ Protocols/Data_processing/EMU_outputs_documentation.md
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1c: Integrate OTU Tables + Taxonomy + Rodent Metadata
#----------------------------------------------------------*
# Purpose:
#   - Clean and pivot Marly's and Melanie's OTU count tables
#   - Join with EMU taxonomy assignments
#   - Integrate with rodent metadata using barcodes
#   - Save fully annotated OTU tables separately for each filtering strategy
#
# ðŸ“„ Script: Scripts/Preprocessing/04a_merge_otu_tables_to_metadata.R
# ðŸ“‚ Outputs:
#   - otu_taxonomy_metadata_marly.csv    (standard filtering)
#   - otu_taxonomy_metadata_melanie.csv (lenient filtering)
message(
"\nðŸ”¹ Step 4.1c: Integrating OTU counts with taxonomy and rodent metadata...")
source(
file.path(scripts_dir, "preprocessing", "04a_merge_otu_tables_to_metadata.R"))
#----------------------------------------------------------*
# 4.1d: Compare EMU Filtering Pipelines
#----------------------------------------------------------*
# This step runs a full RMarkdown comparison between two
# EMU OTU filtering strategies:
#   - Marly's standard filtering
#   - Melanie's lenient filtering
#
# The script performs:
#   â–¸ Read depth summaries
#   â–¸ Alpha diversity comparison (richness, Shannon)
#   â–¸ Rare taxa quantification
#   â–¸ Phylum-level taxonomic composition
#   â–¸ Rarefaction curve visualisation
#   â–¸ NMDS ordination (Bray-Curtis beta diversity)
#
# ðŸ“‚ Outputs:
#   â–¸ HTML report:
# Protocols/Data_processing/04b_compare_filtering_marly_vs_melanie.html
#   â–¸ PDF report:
# Protocols/Data_processing/Comparison_filtering_strategies_Marly_Melanie.pdf
#
#  Read EMU combined abundance counts
emu <- read.delim("Data/processed/28S_Sequencing_Emanuel/emu-combined-tax_id-counts.tsv")
# Separate taxonomic data and count matrix
emuCounts <- emu %>%
select(starts_with("barcode")) %>%
round() %>%
replace(is.na(.), 0)
emuTax <- emu %>%
select(-starts_with("barcode")) %>%
mutate_all(as.character) %>%
mutate_all(~gsub("^$", NA, .)) %>%
dplyr::select(tax_id, superkingdom, phylum, class, order, family, genus, species)
# ðŸ“‹ Load sample metadata
samples <- read.csv("Data/processed/28S_Sequencing_Emanuel/AnimalData28S.csv")
samples$Barcode <- gsub("BC(\\d\\d) *", "barcode\\1", samples$Barcode)
rownames(samples) <- samples$Barcode
# ðŸ“Œ Subset to rodent samples
samples <- samples[samples$project %in% c("rodents", "rodeants"), ]
emuCounts <- emuCounts[, colnames(emuCounts) %in% rownames(samples)]
samples <- samples[colnames(emuCounts), ]  # match order
# ðŸ§ª Build phyloseq object
ps <- phyloseq(
otu_table(emuCounts, taxa_are_rows = TRUE),
tax_table(as.matrix(emuTax)),
sample_data(samples)
)
# ðŸŽ¯ Subset to relevant parasite taxa
ps_parasites <- subset_taxa(ps, phylum %in% c("Nematoda", "Apicomplexa", "Platyhelminthes"))
ps_parasites <- subset_taxa(ps_parasites, !order %in% "Eugregarinorida")  # remove Gregarines
ps_parasites <- subset_taxa(ps_parasites, taxa_sums(ps_parasites) > 1)
# ðŸ“Š Generate heatmap
message("ðŸ”¹ Plotting rodent parasite heatmap...")
png(output_fig, width = 1200, height = 600)
pheatmap(
log10(otu_table(ps_parasites) + 1),
labels_row = tax_table(ps_parasites)[, "species"],
labels_col = sample_data(ps_parasites)$sample_ID,
display_numbers = FALSE,
fontsize_row = 6,
fontsize_col = 8
)
dev.off()
pheatmap(
log10(otu_table(ps_parasites) + 1),
labels_row = tax_table(ps_parasites)[, "species"],
labels_col = sample_data(ps_parasites)$sample_ID,
display_numbers = FALSE,
fontsize_row = 6,
fontsize_col = 8
)
View(emuTax)
write.csv(x = emu, file = "Data/processed/28S_Sequencing_Emanuel/emu_combined_tx_id_counts.csv", row.names = FALSE)
