#   â–¸ NMDS ordination (Bray-Curtis beta diversity)
#
# ðŸ“‚ Outputs:
#   â–¸ HTML report:
# Protocols/Data_processing/04b_compare_filtering_marly_vs_melanie.html
#   â–¸ PDF report:
# Protocols/Data_processing/Comparison_filtering_strategies_Marly_Melanie.pdf
#
#  Read EMU combined abundance counts
emu <- read.delim("Data/processed/28S_Sequencing_Emanuel/emu-combined-tax_id-counts.tsv")
# Separate taxonomic data and count matrix
emuCounts <- emu %>%
select(starts_with("barcode")) %>%
round() %>%
replace(is.na(.), 0)
emuTax <- emu %>%
select(-starts_with("barcode")) %>%
mutate_all(as.character) %>%
mutate_all(~gsub("^$", NA, .)) %>%
dplyr::select(tax_id, superkingdom, phylum, class, order, family, genus, species)
# ðŸ“‹ Load sample metadata
samples <- read.csv("Data/processed/28S_Sequencing_Emanuel/AnimalData28S.csv")
samples$Barcode <- gsub("BC(\\d\\d) *", "barcode\\1", samples$Barcode)
rownames(samples) <- samples$Barcode
# ðŸ“Œ Subset to rodent samples
samples <- samples[samples$project %in% c("rodents", "rodeants"), ]
emuCounts <- emuCounts[, colnames(emuCounts) %in% rownames(samples)]
samples <- samples[colnames(emuCounts), ]  # match order
# ðŸ§ª Build phyloseq object
ps <- phyloseq(
otu_table(emuCounts, taxa_are_rows = TRUE),
tax_table(as.matrix(emuTax)),
sample_data(samples)
)
# ðŸŽ¯ Subset to relevant parasite taxa
ps_parasites <- subset_taxa(ps, phylum %in% c("Nematoda", "Apicomplexa", "Platyhelminthes"))
ps_parasites <- subset_taxa(ps_parasites, !order %in% "Eugregarinorida")  # remove Gregarines
ps_parasites <- subset_taxa(ps_parasites, taxa_sums(ps_parasites) > 1)
# ðŸ“Š Generate heatmap
message("ðŸ”¹ Plotting rodent parasite heatmap...")
png(output_fig, width = 1200, height = 600)
pheatmap(
log10(otu_table(ps_parasites) + 1),
labels_row = tax_table(ps_parasites)[, "species"],
labels_col = sample_data(ps_parasites)$sample_ID,
display_numbers = FALSE,
fontsize_row = 6,
fontsize_col = 8
)
dev.off()
pheatmap(
log10(otu_table(ps_parasites) + 1),
labels_row = tax_table(ps_parasites)[, "species"],
labels_col = sample_data(ps_parasites)$sample_ID,
display_numbers = FALSE,
fontsize_row = 6,
fontsize_col = 8
)
View(emuTax)
write.csv(x = emu, file = "Data/processed/28S_Sequencing_Emanuel/emu_combined_tx_id_counts.csv", row.names = FALSE)
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl, qgraph, vegan
)
# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
# create vectors for selecting relevant columns in the downstream analysis
# Define vector of trapping-relevant columns from rodent_data
trapping_vars <- c(
"Latitude",
"Longitude",
"Morphology_species",
"Sex",
"Age",
"Weight_g",
"Location_type",
"Date"
)
# Define vector of barcode/sequencing-relevant columns
barcode_vars <- c(
"conc_16s__PCR",
"barcode"
)
# Load raw rodent data
rodent_data <- read_csv(file.path(field_raw_tracking, "Rodents_catching_data.csv"))
# Fix species name inconsistencies
rodent_data$Morphology_species <- str_replace_all(rodent_data$Morphology_species,
c("Vole\\?" = "Vole", "House_mouse\\?" = "House_mouse"))
# Correct incorrect dates (if future years detected)
rodent_data$Date <- str_replace_all(rodent_data$Date, c("202[4-9]|2030" = "2023"))
# Handle missing values
rodent_data <- rodent_data %>%
mutate(Sex = ifelse(Sex == "", "unidentified", Sex)) %>%
mutate(Sex = gsub("63", "unidentified", Sex))
message("âœ… Rodent field data cleaned successfully!")
glimpse(rodent_data)
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
View(rodent_data)
# ***********************************************************
# Title: Link Barcode IDs to Rodent Metadata
# Purpose: Merge barcode-to-sample reference with cleaned field metadata
# ***********************************************************
# Load barcode-sample reference file
barcode_ref <- read_csv("data/raw/16S_sequencing/reference_files/barcode_sample_reference.csv")
View(barcode_ref)
# remove the unecessary string in front of the barcode names
barcode_ref$barcode <- str_remove(
string = barcode_ref$barcode,
pattern = "e17a8f2887894f8d7becdbeaafbc97db14bc8e66_EXP-PBC096_")
# remove repate sample name column
barcode_ref <- barcode_ref %>%
dplyr::select(-Sample_ID...6)
# rename now barcode_ref column sample id
barcode_ref <- barcode_ref %>%
dplyr::rename(Sample_ID = Sample_ID...5) %>%
dplyr::select(Sample_ID, conc_16s__PCR, barcode)
# Merge by Sample_ID
rodent_data <- left_join(rodent_data, barcode_ref, by = "Sample_ID")
message("âœ… Barcode metadata linked to rodent data ")
View(rodent_data)
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Linking barcode names to rodent data frame")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
# ***********************************************************
# Title: Namibia Rodent Project - Data Processing & Analysis
# Purpose: This script executes all processing & analysis steps
#          for the rodent microbiome sequencing study.
#
# Authors: Fay Webster, Marly Erazo, Otto Netzel, Lilla Jordan,
#          Emanuel Heitlinger, Conor Noonan, Dong Xia, Melanie Hay
#
# ***********************************************************
# ***********************************************************
# ***********************************************************
# Part 0: 16S Nanopore Preprocessing (External HPC Pipeline)
# ***********************************************************
# Note: The raw 16S Nanopore data were preprocessed outside of R
#       using a shell-based pipeline executed on the MPCDF cluster.
#
# ðŸ§ª Step 0.1: Basecalling & Demultiplexing (Dorado)
# --------------------------------------------------
# Tool: ONT Dorado
# Script: Scripts/Basecalling/dorado_basecall_mpcdf.slurm
#
# Key components:
#   - CUDA module loaded via `module load cuda/11.4`
#   - Basecalling with `--min-qscore 10`
#   - Outputs: BAM files and summary stats
#   - Demultiplexing using `--kit-name EXP-PBC096`
#
# ðŸ“‚ Outputs:
#   - Basecalled reads:         data/raw/ont_fastq/
#   - Summary & BAM:            data/raw/ont_fastq/*.bam, *.txt
# ðŸ§¬ Step 0.2: Quality Filtering & Length Trimming
# --------------------------------------------------
# Filtering performed for full-length 16S reads (1400â€“1800 bp).
# Quality control and stats generated via:
#   - NanoPlot
#   - samtools stats
# Summary metrics (pre- and post-filtering):
#   â–¸ Mean read quality:       Q15.6
#   â–¸ Number of reads:         ~1.57M
#   â–¸ Read length N50:         ~1,393 bp
#   â–¸ Percent reads > Q10:     98.1%
#   â–¸ Percent reads > Q15:     65.1%
#
# ðŸ“Š Quality report:
#   - NanoPlot HTML report (interactive):
#     â–¸ data/raw/16S_sequencing/quality/NanoPlot-report.html
# ðŸ§¬ Step 0.3: Taxonomic Classification (EMU)
# --------------------------------------------------
# Tool: EMU (Exact Mapping of 16S reads)
# Script: Scripts/Basecalling/emu_script.slurm
#
# Key components:
#   - Conda environment activation (`EMU`)
#   - Looping over demultiplexed FASTQ files
#   - Running `emu abundance` with the SILVA database
#
# ðŸ“‚ Outputs:
#   - Taxonomic abundance tables: data/processed/ont_emu_abundance/
#   - One `.tsv` file per sample with tax_id counts and relative abundances
# ðŸ“„ Documentation:
#   - Full pipeline details, filtering criteria, and HPC command logs:
#     â–¸ Protocols/Data_processing/README_16s_data_preprocessing.pdf
# ðŸ§¾ Step 0.4: Sample Tracking Metadata (PCR + Pooling)
# --------------------------------------------------
# The following files document the 16S plate setup, robot buffer input,
# and pooling decisions used to prepare samples for sequencing.
# These are **not used in the downstream R analysis**, but archived
# for provenance and reproducibility.
# ðŸ“„ Documents:
#   - 16S PCR plate metadata:
#   data/raw/16S_sequencing/16s_PCR/20231123_PCR_final.xlsx
#   - Opentrons robot buffer input:
#         data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Buffer CSV_19-03-2024_namibia_plate16s.csv
#   - Opentrons robot sample input:
#         data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample CSV_19-03-2024_namibia_plate16s.csv
#   - Sample pooling design:
#                data/raw/16S_sequencing/16s_PCR/pipetingrobot_muster/Sample_pooling_CSV_03-04-2024.csv
# ***********************************************************
# Part 1: Set Standard Settings & Load Libraries ----
# ***********************************************************
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl, qgraph, vegan
)
# ***********************************************************
# Part 2: Define Project File Paths ----
# ***********************************************************
# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
# create vectors for selecting relevant columns in the downstream analysis
# Define vector of trapping-relevant columns from rodent_data
trapping_vars <- c(
"Latitude",
"Longitude",
"Morphology_species",
"Sex",
"Age",
"Weight_g",
"Location_type",
"Date"
)
# Define vector of barcode/sequencing-relevant columns
barcode_vars <- c(
"conc_16s__PCR",
"barcode"
)
# ***********************************************************
# Part 3: Data Cleaning - Rodent Field Data ----
# ***********************************************************
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
#----------------------------------------------------------*
# 3.1a: Nanodrop DNA Quality Assessment in the Field
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.1a: Archiving early Nanodrop DNA QC (field)...")
#source(file.path(scripts_dir, "preprocessing", "01a_nanodrop_field_qc.R"))
#----------------------------------------------------------*
# 3.3: AMPure Cleanup QC (Marly)
#----------------------------------------------------------*
#message("\nðŸ”¹ Step 3.3: Processing DNA cleanup QC from AMPure protocol...")
#source(file.path(scripts_dir, "preprocessing", "03_dna_cleaning_qc_marly.R"))
# ***********************************************************
# Part 4: Taxonomic Processing - OTU & Phylogenetic Analysis ----
# ***********************************************************
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Linking barcode names to rodent data frame")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
# Paths to files
otu_marly_path <- "data/processed/EMU_output/marly_standard_filtering/otu_counts_marly_standard.tsv"
otu_melanie_path <- "data/processed/EMU_output/melanie_lenient_filtering/otu_counts_melanie_lenient.tsv"
# Load
otu_marly <- read_tsv(otu_marly_path)
otu_melanie <- read_tsv(otu_melanie_path)
# Load barcode metadata (already cleaned and integrated into rodent_data)
barcode_vector <- unique(rodent_data$barcode)
# Clean and pivot Marly's OTU table
otu_marly_long <- otu_marly %>%
rename_with(~ str_remove(.x, "e17a8f2887894f8d7becdbeaafbc97db14bc8e66_EXP-PBC096_")) %>%
pivot_longer(-tax_id, names_to = "barcode", values_to = "count_marly") %>%
filter(barcode %in% barcode_vector)
# Clean and pivot Melanie's OTU table
otu_melanie_long <- otu_melanie %>%
rename_with(~ str_remove(.x, "e17a8f2887894f8d7becdbeaafbc97db14bc8e66_EXP-PBC096_")) %>%
pivot_longer(-tax_id, names_to = "barcode", values_to = "count_melanie") %>%
filter(barcode %in% barcode_vector)
message("âœ… Merged long-format OTU counts from Marly & Melanie saved to: data/processed/EMU_output/otu_counts_long_combined.csv")
#----------------------------------------------------------*
# Step 4.1c: Load EMU Taxonomy Tables (Marly vs Melanie)
#----------------------------------------------------------*
message("ðŸ”¹ Loading taxonomy tables for Marly and Melanie...")
tax_marly_path   <- file.path(processed_data, "EMU_output", "marly_standard_filtering", "taxonomy_marly_standard.tsv")
tax_melanie_path <- file.path(processed_data, "EMU_output", "melanie_lenient_filtering", "taxonomy_melanie_lenient.tsv")
tax_marly   <- read_tsv(tax_marly_path, show_col_types = FALSE)
tax_melanie <- read_tsv(tax_melanie_path, show_col_types = FALSE)
#----------------------------------------------------------*
# Step 4.1d: Merge OTU counts with taxonomy
#----------------------------------------------------------*
message("ðŸ”¹ Merging OTU counts with taxonomy tables...")
otu_marly_annotated <- otu_marly_long %>%
left_join(tax_marly, by = "tax_id")
otu_melanie_annotated <- otu_melanie_long %>%
left_join(tax_melanie, by = "tax_id")
#----------------------------------------------------------*
# Step 4.1e: Merge annotated OTU + taxonomy with rodent metadata
#----------------------------------------------------------*
message("ðŸ”¹ Merging annotated OTU counts with rodent metadata...")
otu_marly_full <- otu_marly_annotated %>%
left_join(rodent_data, by = "barcode")
otu_melanie_full <- otu_melanie_annotated %>%
left_join(rodent_data, by = "barcode")
#----------------------------------------------------------*
# Step 4.1f: Save integrated datasets
#----------------------------------------------------------*
message("ðŸ’¾ Saving merged OTU + taxonomy + metadata tables...")
write_csv(otu_marly_full,
file.path(processed_data, "EMU_output", "marly_standard_filtering",
"otu_taxonomy_metadata_marly.csv"))
write_csv(otu_melanie_full,
file.path(processed_data, "EMU_output", "melanie_lenient_filtering",
"otu_taxonomy_metadata_melanie.csv"))
# remove unecessary files
rm(otu_marly, otu_marly_annotated, otu_marly_long, otu_marly_path,
otu_melanie, otu_melanie_annotated, otu_melanie_long, otu_melanie_path,
tax_marly, tax_melanie)
glimpse(otu_marly_full)
t
t
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl, qgraph, vegan
)
# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
# create vectors for selecting relevant columns in the downstream analysis
# Define vector of trapping-relevant columns from rodent_data
trapping_vars <- c(
"Latitude",
"Longitude",
"Morphology_species",
"Sex",
"Age",
"Weight_g",
"Location_type",
"Date"
)
# Define vector of barcode/sequencing-relevant columns
barcode_vars <- c(
"conc_16s__PCR",
"barcode"
)
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Linking barcode names to rodent data frame")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
# Count species occurrences
species_count <- rodent_data %>%
group_by(Morphology_species) %>%
summarize(count = n())
# Generate bar plot
p <- ggplot(species_count, aes(x = Morphology_species, y = count, fill = Morphology_species)) +
geom_bar(stat = "identity") +
labs(title = "Distribution of Rodent Species", x = "Species", y = "Count") +
theme_minimal()
p
# Read processed rodent data
rodent_data <- read_csv("data/processed/cleaned_rodent_data.csv")
# Ensure Longitude and Latitude are numeric
rodent_data <- rodent_data %>%
mutate(Longitude = as.numeric(Longitude),
Latitude = as.numeric(Latitude)) %>%
filter(!is.na(Longitude) & !is.na(Latitude))  # Remove missing coordinates
# Ensure Longitude and Latitude are numeric
rodent_data <- rodent_data %>%
mutate(Longitude = as.numeric(Longitude),
Latitude = as.numeric(Latitude)) %>%
filter(!is.na(Longitude) & !is.na(Latitude))  # Remove missing coordinates
df_sf <- st_as_sf(rodent_data, coords = c("Longitude", "Latitude"), crs = 4326)
# Extract Longitude & Latitude back into separate columns for Leaflet compatibility
df_sf <- df_sf %>%
mutate(Longitude = st_coordinates(.)[, 1],
Latitude = st_coordinates(.)[, 2])
m <- leaflet(df_sf) %>%
addTiles() %>%
addCircleMarkers(lng = ~Longitude, lat = ~Latitude, popup = ~Morphology_species,
color = "blue", radius = 3, opacity = 0.8) %>%
addLegend("bottomright", pal = colorFactor(topo.colors(10), df_sf$Morphology_species),
values = df_sf$Morphology_species, title = "Species")
message("âœ… Geographical mapping completed!")
m  # Display the map
knitr::opts_chunk$set(echo = TRUE)
n = 23
STBR = 10 * 4 * n
cat("STBR = ", STBR,"ÂµL")
FP = 0.8 * 4 * n
cat("Forward Primer = ", FP,"ÂµL")
RP = 0.8 * 4 * n
cat("Reverse Primer = ", RP,"ÂµL")
H20 = 7.4 * 4 * n
cat("H20 = ", H20,"ÂµL")
# Increase max overlaps for better plotting
options(ggrepel.max.overlaps = Inf)
# Set a reproducible seed
set.seed(13102023)
# Load & install required packages using pacman
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
tidyverse, janitor, readr, lubridate, ggplot2, phyloseq, vegan,
corrplot, patchwork, ggrepel, RColorBrewer, pheatmap, caret,
randomForest, rfUtilities, optimx, ggpubr, FactoMineR, factoextra,
leaflet, kableExtra, broom, magrittr, data.table, sf, rnaturalearth,
RColorBrewer, tmap, mapview, cowplot, magick, readxl, qgraph, vegan
)
# Dynamically detect the working directory
project_root <- here::here()
# Define primary directories
data_dir       <- file.path(project_root, "data")
raw_data       <- file.path(data_dir, "raw")
field_raw_tracking <- file.path(raw_data, "Field_tracking_data")
processed_data <- file.path(data_dir, "processed")
metadata_dir   <- file.path(data_dir, "metadata")
results_dir    <- file.path(project_root, "results")
figures_dir    <- file.path(results_dir, "figures")
tables_dir     <- file.path(results_dir, "tables")
scripts_dir    <- file.path(project_root, "scripts")
# create vectors for selecting relevant columns in the downstream analysis
# Define vector of trapping-relevant columns from rodent_data
trapping_vars <- c(
"Latitude",
"Longitude",
"Morphology_species",
"Sex",
"Age",
"Weight_g",
"Location_type",
"Date"
)
# Define vector of barcode/sequencing-relevant columns
barcode_vars <- c(
"conc_16s__PCR",
"barcode"
)
#----------------------------------------------------------*
# 3.1: Import & Clean Rodent Field Data
#----------------------------------------------------------*
message("\nðŸ”¹ Step 3.1: Cleaning rodent field data...")
source(file.path(scripts_dir, "preprocessing", "1_import_clean_field_data.R"))
#----------------------------------------------------------*
#----------------------------------------------------------*
# 4.1a: Rename OTU Columns Using Sample Metadata
#----------------------------------------------------------*
message("\nðŸ”¹ Step 4.1a: Linking barcode names to rodent data frame")
source(file.path(scripts_dir, "preprocessing", "02_link_barcode_to_metadata.R"))
